{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_4_Ross.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAYOJPFyxXXp8Bcj5E/Rj9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joshua-Hill-Science/Landscapes/blob/ross/Project_4_Ross.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TcWD2aE23qP"
      },
      "source": [
        "! unzip sample_data/archive.zip &> /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MET0SY8L5sxK"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0sJv_fOFI9N"
      },
      "source": [
        "**Reading in image data and scaling it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQwKj-cd5tLY"
      },
      "source": [
        "train_data_dir = 'seg_train/seg_train'\n",
        "test_data_dir = 'seg_test/seg_test'\n",
        "\n",
        "test_generator = ImageDataGenerator(rescale = 1.0/255).flow_from_directory(\n",
        "        test_data_dir, \n",
        "        target_size=(64, 64), batch_size=64)\n",
        "\n",
        "train_generator = ImageDataGenerator(rescale = 1.0/255).flow_from_directory(\n",
        "        train_data_dir, \n",
        "        target_size=(64, 64), batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbHRpPDSFUON"
      },
      "source": [
        "**Baseline Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKzKotD45tNw"
      },
      "source": [
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "model = Sequential() \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(64, 64, 3),))# use_bias=True)) \n",
        "model.add(MaxPooling2D((2, 2))) \n",
        "model.add(Flatten()) \n",
        "model.add(Dense(128, activation='relu',)) #use_bias=True)) \n",
        "model.add(Dense(6, activation='sigmoid',))# use_bias=True))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmcQjTd84ZKV"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kset46y6SYz"
      },
      "source": [
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=10,\n",
        "        validation_data = test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTYiHU7uGV6f"
      },
      "source": [
        "**Graphing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJSb9T7qF4AR"
      },
      "source": [
        "def history_graph(history):\n",
        "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(16, 6))\n",
        "    metrics_loss = ['loss','val_loss']\n",
        "    for metric_loss in metrics_loss:\n",
        "        ax1.plot(history.history[metric_loss], label=metric_loss)\n",
        "        ax1.legend()\n",
        "        ax1.set_title(f\"Model's Loss per Epoch\")\n",
        "    metrics_acc = ['accuracy','val_accuracy']\n",
        "    for metric_acc in metrics_acc:\n",
        "        ax2.plot(history.history[metric_acc], label=metric_acc)\n",
        "        ax2.legend()\n",
        "        ax2.set_title(f\"Model's Accuracy per Epoch\")\n",
        "    plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAhy3xqRF4Yz"
      },
      "source": [
        "history_graph(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qbgIR9RQRLH"
      },
      "source": [
        "**Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXG8bvd_RfEu"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "early_stopping = [EarlyStopping(monitor='val_loss', patience=4), \n",
        "                  ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NejErh4RUPs"
      },
      "source": [
        "model = Sequential() \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(64, 64, 3),))# use_bias=True)) \n",
        "model.add(MaxPooling2D((2, 2))) \n",
        "model.add(Flatten()) \n",
        "model.add(Dense(128, activation='relu',)) #use_bias=True)) \n",
        "model.add(Dense(6, activation='sigmoid',))# use_bias=True))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rsmz7zIRUbC"
      },
      "source": [
        "history2 = model.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=10,\n",
        "        callbacks = early_stopping,\n",
        "        validation_data = test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcafH98t6Sbh"
      },
      "source": [
        "from keras.models import load_model\n",
        "saved_model = load_model('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhA6NQEIWaAg"
      },
      "source": [
        "results_train = saved_model.evaluate_generator(train_generator, 400)\n",
        "print(results_train)\n",
        "\n",
        "print('----------')\n",
        "\n",
        "results_test = saved_model.evaluate_generator(test_generator, 400)\n",
        "print(results_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UD7XzbmalEF"
      },
      "source": [
        "**L2 Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRRGqLczaqPA"
      },
      "source": [
        "l2_reg = Sequential() \n",
        "l2_reg.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.005), input_shape=(64, 64, 3),))\n",
        "l2_reg.add(MaxPooling2D((2, 2))) \n",
        "l2_reg.add(Flatten()) \n",
        "l2_reg.add(Dense(128,kernel_regularizer=regularizers.l2(0.005), activation='relu',))\n",
        "l2_reg.add(Dense(6, activation='sigmoid',))\n",
        "\n",
        "l2_reg.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSbaAdyma2Rv"
      },
      "source": [
        "l2_reg_hist = l2_reg.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=30,\n",
        "        validation_data = test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqQlBFgPktRm"
      },
      "source": [
        "def history_graph(history):\n",
        "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(16, 6))\n",
        "    metrics_loss = ['loss','val_loss']\n",
        "    for metric_loss in metrics_loss:\n",
        "        ax1.plot(history.history[metric_loss], label=metric_loss)\n",
        "        ax1.legend()\n",
        "        ax1.set_title(f\"Model's Loss per Epoch\")\n",
        "    metrics_acc = ['accuracy','val_accuracy']\n",
        "    for metric_acc in metrics_acc:\n",
        "        ax2.plot(history.history[metric_acc], label=metric_acc)\n",
        "        ax2.legend()\n",
        "        ax2.set_title(f\"Model's Accuracy per Epoch\")\n",
        "    plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZSe-0NcoapP"
      },
      "source": [
        "history_graph(l2_reg_hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlLxJ-DBgk6n"
      },
      "source": [
        "**l1 Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH2_SXN5a2WQ"
      },
      "source": [
        "l1_reg = Sequential() \n",
        "l1_reg.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=regularizers.l1(0.005), input_shape=(64, 64, 3),))\n",
        "l1_reg.add(MaxPooling2D((2, 2))) \n",
        "l1_reg.add(Flatten()) \n",
        "l1_reg.add(Dense(128,kernel_regularizer=regularizers.l1(0.005), activation='relu',))\n",
        "l1_reg.add(Dense(6, activation='sigmoid',))\n",
        "\n",
        "l1_reg.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr1YSWOBa2Z7"
      },
      "source": [
        "l1_reg_hist = l2_reg.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=10,\n",
        "        callbacks = early_stopping,\n",
        "        validation_data = test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ-GiCNllB-4"
      },
      "source": [
        "**Dropout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr4AT7tHa2cY"
      },
      "source": [
        "drop = Sequential() \n",
        "drop.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=regularizers.l1(0.005), input_shape=(64, 64, 3),))\n",
        "drop.add(MaxPooling2D((2, 2))) \n",
        "drop.add(Dropout(0.25))\n",
        "drop.add(Flatten()) \n",
        "drop.add(Dense(128,kernel_regularizer=regularizers.l2(0.005), activation='relu',))\n",
        "drop.add(Dropout(0.25))\n",
        "drop.add(Dense(6, activation='sigmoid',))\n",
        "drop.add(Dropout(0.25))\n",
        "\n",
        "drop.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5PDeKyIa2e-"
      },
      "source": [
        "drop_hist = l2_reg.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=10,\n",
        "        callbacks = early_stopping,\n",
        "        validation_data = test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4AwzNpvv5v2"
      },
      "source": [
        "**Dropout and L2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIzgWpMtv8yy"
      },
      "source": [
        "all = Sequential() \n",
        "all.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.002), input_shape=(64, 64, 3),))\n",
        "all.add(MaxPooling2D((2, 2))) \n",
        "all.add(Flatten())\n",
        "all.add(Dropout(0.25)) \n",
        "all.add(Dense(128,kernel_regularizer=regularizers.l2(0.004), activation='relu',))\n",
        "all.add(Dropout(0.25))\n",
        "all.add(Dense(64,kernel_regularizer=regularizers.l2(0.004), activation='relu',))\n",
        "all.add(Dropout(0.25))\n",
        "all.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "\n",
        "all.compile(loss='categorical_crossentropy',\n",
        "              optimizer='nadam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH4mLD6Bv9Xr"
      },
      "source": [
        "all_hist = all.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=30,\n",
        "        validation_data = test_generator)\n",
        "        #callbacks = early_stopping,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GReUZL56rN_"
      },
      "source": [
        "history_graph(all_hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fdfU-TuHB1r"
      },
      "source": [
        "**Adding another L2 layer to help the fluctuation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TryfpJs8-eae"
      },
      "source": [
        "l5_reg = Sequential() \n",
        "l5_reg.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.005), input_shape=(64, 64, 3),))\n",
        "l5_reg.add(MaxPooling2D((2, 2))) \n",
        "l5_reg.add(Flatten()) \n",
        "l5_reg.add(Dense(128,kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
        "l5_reg.add(Dense(64,kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
        "l5_reg.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "l5_reg.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UARo_c3-orhn"
      },
      "source": [
        "history_5 = l5_reg.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=10,\n",
        "        validation_data = test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgXiL-52HQH9"
      },
      "source": [
        "**Final Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tiq1rzkoroY"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "final = Sequential() \n",
        "final.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(0.003), input_shape=(64, 64, 3),))\n",
        "final.add(MaxPooling2D((2, 2))) \n",
        "final.add(Flatten())\n",
        "final.add(Dropout(0.30)) \n",
        "final.add(Dense(128,kernel_regularizer=regularizers.l2(0.003), activation='relu',))\n",
        "final.add(Dropout(0.30))\n",
        "final.add(Dense(6, activation='sigmoid'))\n",
        "#default= 0.001\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "final.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nos5UYq1wnTN"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
        "final_model = final.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=22,\n",
        "        validation_data = test_generator,\n",
        "        callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeP4dMWCB82Y"
      },
      "source": [
        "model = tensorflow.keras.models.load_model(\"best_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnXPulQqHzcW"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gBCtl82ppCA"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxNOPL5ippF5"
      },
      "source": [
        "im = Image.open(\"seg_pred/seg_pred/10012.jpg\")\n",
        "\n",
        "im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9xt5AWxHsMQ"
      },
      "source": [
        "image = tf.keras.preprocessing.image.load_img('seg_pred/seg_pred/10012.jpg', target_size=((64,64)))\n",
        "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "input_arr = np.array([input_arr])\n",
        "predictions = final_model.predict(input_arr)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpmitfdIppME"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY0AyeOippO6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}